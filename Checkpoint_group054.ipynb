{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will Your Car Hold Its Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Taylor Drennen\n",
    "- Jaime Altamirano-Ramirez\n",
    "- Geoffrey Hand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Our project’s main objective is to create a model that predicts whether the used car will hold its value based on the year, model, mileage, and maker of the car. We will be using a dataset that contains used car prices along with the features stated above to train the model. In addition, to determine whether the used cars listed in the data held their value, we will determine the standard depreciation threshold based on Manufacturer Suggested Retail Price (MSRP) extracted from the CARFAX website and create a new feature of the data. The model will be trained using a multivariate dataset classification algorithm such as a Support-Vector Machine (SVM) and K-Nearest Neighbors (KNN). We will be using cross-validation to measure the performance of this model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In the modern society, it is undeniable that the car is essial asset to live. However, it is also considered luxury item due to its expense. Not everyone can afford brand new car; therefor, many people opt out for used car instead. During pandemic, due to low supply of semiconductor chips, the car production declined. As a result, there were not enough new cars for people to purchase, forcing car buyers into used car market  instead <a name=\"fried\"></a>[<sup>[3]</sup>](#fried).  SInce there is always a demand for used car, there is also demand for people to sell their cars. The common concern people may have when they sell their cars is whether they are getting good deal out of it. That is the question our model will be answering. \n",
    "\n",
    "In the past, there were several other projects with purpose of price prediction of Used Cars. In 2021, IEEE published their used car prediction model. Many of these project focuses on price prediction for seller. The used car dealer spend their time and effort on the market to assess used vehicles.They check the vehicle's model, year of production, condition, and mileage, among others <a name=\"ieee\"></a>[<sup>[4]</sup>](#ieee). Thus, the used car price prediction model typically used those feature to predict the price. \n",
    "\n",
    "This project also go into price prediction just like IEEE project. However, we will be evaluating whether the price is fair. To evaluate this, we wil lexamine car depreciation rate. According to Carmax,  the value of a new vehicle drops by about 20% in the first year of ownership and over the next four years, you can expect your car to lose roughly 15% of its value each year <a name=\"carmax\"></a>[<sup>[5]</sup>](#carmax). Based on this fact, we can calculate standard depreciation threshold that decides whether the used car price is following the standard of depreciation rate and if not, it means that car did not hold it’s value. This will allow seller to see if they are selling the car for rightful price. In addition, buyer can see if they are paying the fair price. Our goal is for this model to benefit sellers, buyers, and car manufacturers in the used cars market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem we aim to solve is whether a car will hold its market value at the time of selling. To elaborate, we plan on creating a reliable algorithm that can determine whether a car is likely to be sold at or above its depreciation value at the point of sale. With car prices nearing a record high, the desire to know whether a used car will hold its value is an important decision car owners are having to make. Given that there are a lot of variables that come into play when selling a car (e.g.make, model, mileage, location, year, condition, etc), and that some variables may hold more weight than others (such as the year of a car being a bigger factor than its mileage), we intend to compare a few models while optimizing our hyperparameters. We plan on turning our string data, such as location, into numerical data to align with the bulk of our expected variables which will be float types for our code. On a separate note, the global automobile market is expected to continue rising and the compound annual growth rate is expected to be 3.7% from 2020-to 2030 <a name=\"renub\"></a>[<sup>[1]</sup>](#renub) . Therefore, more used cars will be entering the market and allow for future data collection and analysis to be done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "#### Used car price dataset\n",
    "https://www.kaggle.com/datasets/harikrishnareddyb/used-car-price-predictions/code\n",
    "- 8 Variables\n",
    "- 852122 Observations\n",
    "- May take out columns that we are not using and check for any Nan Variable\n",
    "- Need to convert a string variable to an integer through one-hot encoding \n",
    "\n",
    "#### Manufacturer Suggested Retail Price (MSRP)\n",
    "https://www.cars.com/research/{make}-{model}-{year}\n",
    "- Create a new dataset by collecting the MSRP of all vehicles in the previous dataset from the website linked above\n",
    "- Retrieve MSRP from the website\n",
    "- Model, year, and make is provided by the previous dataset\n",
    "\n",
    "Based on the MSRP and price of the car, we will create a new feature called “hold value” which holds a boolean value that represents whether the price of the car is below the depreciation threshold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "For the purpose of this project, we will need a multivariate dataset classification model. The final model should take in the year, model, maker, and mileage of the car and determine if it will hold its value or in other words if the predicted price would be above the standard depreciation threshold.  As a group, we decided to compare the SVM and KNN algorithms to determine the best model for this project. \n",
    " \n",
    "#### Support-Vector Machine (SVM)\n",
    "\n",
    "SVM is a supervised learning technique; thus we will be training this model with the dataset.  We will be finding hyperplanes that divide the data into two clusters that determine whether the predicting datapoint holds value or not. SVM uses a kernel function to help calculate hyperplanes. This allows us to have a smoother calculation for the multidimensional dataset. For this project, we will use a linear kernel.  This model will be implemented using the SVM function from the sklearn library. \n",
    "\n",
    "To optimize this model, we will be changing the margin. The margin is the distance between the hyperplane and the nearest data, also known as the supporting vector. For the purpose of optimization, we want to maximize the margin; therefore, different weight vectors can be considered during evaluation.\n",
    "\n",
    "#### K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN is also a supervised learning technique; thus we will be training this model with the dataset. The KNN algorithm is simple, we are looking for a label of training data that has the shortest Euclidean distance from the predicted data point. K value determines how many data points will be taken into consideration. It is a majority rule technique, and it has non-linear decision boundaries so it may be more effective for training data with multiple features. To simplify the implementation, we will also be using the KNeighborsClassifiers function from the sklearn library.\n",
    "\n",
    "The concern with this algorithm is computation cost. The cost of calculating the distance between a new point and each existing point is very high. Since we are going to be using high-dimensional data, the cost of computation can be high. \n",
    "\n",
    "The KNN algorithm can be optimized by finding the most effective K value. We will be evaluating multiple K values\n",
    "\n",
    "#### Required Libraries\n",
    "- numpy\n",
    "- requests\n",
    "- bs4\n",
    "- tqdm\n",
    "- black\n",
    "- ipykernel\n",
    "- pandas\n",
    "- matplotlib\n",
    "- isort\n",
    "- pylint\n",
    "- jinja2\n",
    "- sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "\n",
    "We will be using simple cross-validation to evaluate our model performance. We will divide the randomized data into a training set and a validation set.  The output of the model that was trained will be compared with the validation set to get the confusion matrix. The final score that determines the performance of our model will be given by the F1 score. Initially, we will look at Accuracy to see if our model is good enough to predict correctly. Then, we will look at the F1 score to minimize false negatives. \n",
    "\n",
    "##### Accuracy: The ability of a model to accurately predict.\n",
    "$Accuray = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "##### Recall/Sensitivity:  The ability of a model to find all the relevant cases within a data set.\n",
    "$Recall = \\frac{TP}{TP+FN}$\n",
    "\n",
    "##### Precision:  The ability of a model to identify only the relevant data points.\n",
    "$Precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "##### F1 Score: optimal blend of precision and recall \n",
    "$F1 = \\frac{2*Recall*Precision}{Sensitivity + Recall}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'true_car_listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c55f5b473238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true_car_cleaned.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \"\"\"\n\u001b[1;32m-> 1357\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'true_car_cleaned.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c55f5b473238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# source: https://www.kaggle.com/datasets/harikrishnareddyb/used-car-price-predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true_car_listings.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappend_msrp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1863\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1864\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \"\"\"\n\u001b[1;32m-> 1357\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'true_car_listings.csv'"
     ]
    }
   ],
   "source": [
    "# install reqs\n",
    "%pip install --quiet -r requirements.txt\n",
    "\n",
    "from data_cleaning import clean_dataframe, append_msrp, append_retains_value, get_expected_value\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cleaning takes ~20mins, so we try to avoid repeating it\n",
    "try:\n",
    "    df = pd.read_csv(\"true_car_cleaned.csv\", index_col=0)\n",
    "except FileNotFoundError:\n",
    "    # source: https://www.kaggle.com/datasets/harikrishnareddyb/used-car-price-predictions\n",
    "    df = pd.read_csv(\"true_car_listings.csv\")\n",
    "    df = clean_dataframe(df)\n",
    "    df = append_msrp(df)\n",
    "    df = append_retains_value(df)\n",
    "    df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the variable that will eventually become our class, `retains_value`, has very little correlation to `MSRP` and `Mileage`. This may suggest more of a connection between Make, Model, and specific model-years (since they aren't featured in this numerical-only matrix).\n",
    "\n",
    "`expected_value` is strongly correlated to `Price`, meaning on average our metric of depreciation mostly holds true. However, with this machine learning model we hope to further granularize this and give a better understanding of how different features affect how value is held (or not held)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of price differences\n",
    "df.apply(lambda x: (x['Price'] - x['expected_value']) / (x['Price'] + x['expected_value']), axis=1).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should drop `Price`, since our model should neither know it nor predict it\n",
    "df = df[['Year', 'Mileage', 'Make', 'Model', 'MSRP', 'retains_value']]\n",
    "df['retains_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "X = df.drop('retains_value', axis=1)\n",
    "y = df['retains_value']\n",
    "\n",
    "numeric_features = ['Year', 'Mileage', 'MSRP']\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "categorical_features = ['Make', 'Model']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "# classifier = LinearSVC(verbose=1, dual=False)\n",
    "# classifier = SVC(verbose=1, kernel='linear')\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier(min_impurity_decrease=0.0002)\n",
    "\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", classifier)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing hyperparameters:\n",
    "\n",
    "```\n",
    "min_impurity_decrease=0\n",
    "0.7268\n",
    "min_impurity_decrease=0.0001\n",
    "0.76915\n",
    "min_impurity_decrease=0.001\n",
    "0.69285\n",
    "min_impurity_decrease=0.01\n",
    "0.55105\n",
    "min_impurity_decrease=0.1\n",
    "0.50345\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "params = np.linspace(0, 0.001, 20)\n",
    "scores = []\n",
    "for param in params:\n",
    "    # print(f\"min_impurity_decrease={param}\")\n",
    "    classifier = tree.DecisionTreeClassifier(min_impurity_decrease=param)\n",
    "\n",
    "    clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", classifier)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    # print(score)\n",
    "    scores.append(score)\n",
    "\n",
    "best_score = max(scores)\n",
    "best_param = params[scores.index(best_score)]\n",
    "print(f\"Best parameter={best_param} yields score {best_score}\")\n",
    "plt.plot(params, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ada35402aa66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot of decision tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'plot_tree.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 6000x4000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of decision tree\n",
    "plt.figure(dpi=1000)\n",
    "tree.plot_tree(clf['classifier'], class_names=True)\n",
    "plt.savefig('plot_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3e968d462e85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# adapted from @gbhand's D6\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = clf.predict_proba(X_test)[:,1]\n",
    "fps = []\n",
    "tps = []\n",
    "for threshold in np.linspace(0,1,1000):\n",
    "    y_pred = scores > threshold\n",
    "    true_negatives, false_positives, false_negatives, true_positives = confusion_matrix(y_test, y_pred).ravel()\n",
    "    fps.append(false_positives / (false_positives + true_negatives)) # add false positive rate\n",
    "    tps.append(true_positives / (true_positives + false_negatives)) # add true positive rate\n",
    "\n",
    "fpr = fps\n",
    "tpr = tps\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, scores)\n",
    "\n",
    "# plotting the ROC curve\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "print('Area under the Receiver Operating Characteristic curve:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy\n",
    "\n",
    "The data we are retrieving from Kaggle contains attributes of the car and the value it was sold for. Given that we are not collecting or using personal information of individuals, we do not have to worry about informed consent of individuals. If we were to collect further data, we would discard any identifiable information from the individual or car- such as vehicle identification number. \n",
    "\n",
    "Although not yet apparent, we do speculate that there could be some bias towards the data collection for specific regions since more than 20% of the data collected comes from California and Texas, but this could be due to these two states being the most populated in the United States <a name=\"uscb\"></a>[<sup>[2]</sup>](#uscb). Thus, we plan on using the state location of a vehicle as an independent variable but also may experiment with stratified k-fold cross validation. \n",
    "\n",
    "Although the model may be used to price hike a car that would otherwise be sold at a lower value or low-ball a seller who would otherwise sell the car at a higher price, we believe that the accurate representation of whether a used car will hold its value is important for such decision-making. There could be a more extreme case where the brand of vehicles can be looked down upon after noting that the car value does not hold. In such a situation, we would make a clear statement that the maker of the car is not the sole defining factor and that important variables, like mileage and year, play a large role in the value of cars. Moreover, we would hope to further develop the model by potentially weighing variables differently and observing learning curves to determine if the model would lead to more accurate results. \n",
    "\n",
    "As of now, we have talks of testing and monitoring for a concept drift but are unclear as to how we would implement it. After solidifying our model, we will further explain the limitations, shortcomings, and biases that exist in our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The team will meet every week to check in on each other’s progress\n",
    "- All decision making will be made with a majority vote\n",
    "- The team will communicate primarily on Discord and will report the status of their part of the work if necessary\n",
    "- Keep each other accountable for deadlines decided as a team ( most likely the day of the meeting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/24  | Before 11:59 PM  |  Work on project proposal (Taylor)  | Turni in project proposal |\n",
    "| 5/4  | 7:00 PM  | NA   | Discuss Project Idea, Work on Proposal |\n",
    "| 5/19  | 5:00 PM  | Work on Proposal   | Project Checkpoint, Clean Up Dataset, Rediscuss model selection |\n",
    "| 5/21  | 4:00 PM  | Work on Checkpoint   | Run data through model, compare/evaluate models |\n",
    "| 6/1  | 4:00 PM  | Model Optimization  | Final Writeup, Evaluate Final Model Performance |\n",
    "| 6/11  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"renub\"></a>1.[^](#renub): Global Automotive Market, Growth & Forecast, Impact of Coronavirus, Industry Trends, By Region, Opportunity Company Analysis. 2021. Research and Markets, https://www.researchandmarkets.com/reports/5447681/global-automotive-market-growth-and-forecast?utm_source=BW&utm_medium=PressRelease&utm_code=9r6nph&utm_campaign=1603404+-+Global+Automotive+Market%3a+COVID-19%2c+Growth+%26+Forecast+2020-2030&utm_exec=joca. Accessed 20th May 2022.<br> \n",
    "<a name=\"uscb\"></a>2.[^](#uscb): U.S. Census Bureau quickfacts: Idaho. (n.d.). Retrieved May 21, 2022, from https://www.census.gov/quickfacts/geo/chart/ID/PST045221<br>\n",
    "<a name=\"fried\"></a>3.[^](#fried): Fried, Carla, et al. “Dealers Might Not Profit from Soaring Used-Car Prices.” UCLA Anderson Review, UCLA Anderson Review, 16 Feb. 2022, https://anderson-review.ucla.edu/dealers-might-not-profit-from-soaring-used-car-prices/.  <br>\n",
    "<a name=\"ieee\"></a>4.[^](#ieee):Jin, Chuyang. “Price Prediction of Used Cars Using Machine Learning.” IEEE Xplore, IEEE, 8 Feb. 2022, https://ieeexplore.ieee.org/document/9696839. <br>\n",
    "<a name=\"carmax\"></a>5.[^](#carmax): Popely, Rick. “Car Depreciation: How Much It Costs You.” CARFAX, CARFAX, 26 Apr. 2021, https://www.carfax.com/blog/car-depreciation. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4933dd0d3d9dda55d6f7a0e31c40ff4e25ee4bdfb7a3b4eb12112cbc4dbf9974"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
