{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will Your Car Hold Its Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Taylor Drennen\n",
    "- Jaime Altamirano-Ramirez\n",
    "- Geoffrey Hand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Our project’s main objective is to create a model that predicts whether the used car will hold its value based on the year, model, mileage, and maker of the car. We will be using a dataset that contains used car prices along with the features stated above to train the model. In addition, to determine whether the used cars listed in the data held their value, we will determine the standard depreciation threshold based on Manufacturer Suggested Retail Price (MSRP) extracted from the CARFAX website and create a new feature of the data. The model will be trained using a multivariate dataset classification algorithm such as a Support-Vector Machine (SVM) and K-Nearest Neighbors (KNN). We will be using cross-validation to measure the performance of this model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "#### Used car price dataset\n",
    "https://www.kaggle.com/datasets/harikrishnareddyb/used-car-price-predictions/code\n",
    "- 8 Variables\n",
    "- 852122 Observations\n",
    "- May take out columns that we are not using and check for any Nan Variable\n",
    "- Need to convert a string variable to an integer through one-hot encoding \n",
    "\n",
    "#### Manufacturer Suggested Retail Price (MSRP)\n",
    "https://www.cars.com/research/{make}-{model}-{year}\n",
    "- Create a new dataset by collecting the MSRP of all vehicles in the previous dataset from the website linked above\n",
    "- Retrieve MSRP from the website\n",
    "- Model, year, and make is provided by the previous dataset\n",
    "\n",
    "Based on the MSRP and price of the car, we will create a new feature called “hold value” which holds a boolean value that represents whether the price of the car is below the depreciation threshold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "For the purpose of this project, we will need a multivariate dataset classification model. The final model should take in the year, model, maker, and mileage of the car and determine if it will hold its value or in other words if the predicted price would be above the standard depreciation threshold.  As a group, we decided to compare the SVM and KNN algorithms to determine the best model for this project. \n",
    " \n",
    "#### Support-Vector Machine (SVM)\n",
    "\n",
    "SVM is a supervised learning technique; thus we will be training this model with the dataset.  We will be finding hyperplanes that divide the data into two clusters that determine whether the predicting datapoint holds value or not. SVM uses a kernel function to help calculate hyperplanes. This allows us to have a smoother calculation for the multidimensional dataset. For this project, we will use a linear kernel.  This model will be implemented using the SVM function from the sklearn library. \n",
    "\n",
    "To optimize this model, we will be changing the margin. The margin is the distance between the hyperplane and the nearest data, also known as the supporting vector. For the purpose of optimization, we want to maximize the margin; therefore, different weight vectors can be considered during evaluation.\n",
    "\n",
    "#### K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN is also a supervised learning technique; thus we will be training this model with the dataset. The KNN algorithm is simple, we are looking for a label of training data that has the shortest Euclidean distance from the predicted data point. K value determines how many data points will be taken into consideration. It is a majority rule technique, and it has non-linear decision boundaries so it may be more effective for training data with multiple features. To simplify the implementation, we will also be using the KNeighborsClassifiers function from the sklearn library.\n",
    "\n",
    "The concern with this algorithm is computation cost. The cost of calculating the distance between a new point and each existing point is very high. Since we are going to be using high-dimensional data, the cost of computation can be high. \n",
    "\n",
    "The KNN algorithm can be optimized by finding the most effective K value. We will be evaluating multiple K values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "\n",
    "We will be using simple cross-validation to evaluate our model performance. We will divide the randomized data into a training set and a validation set.  The output of the model that was trained will be compared with the validation set to get the confusion matrix. The final score that determines the performance of our model will be given by the F1 score. Initially, we will look at Accuracy to see if our model is good enough to predict correctly. Then, we will look at the F1 score to minimize false negatives. \n",
    "\n",
    "##### Accuracy: The ability of a model to accurately predict.\n",
    "$Accuray = \\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "\n",
    "##### Recall/Sensitivity:  The ability of a model to find all the relevant cases within a data set.\n",
    "$Recall = \\frac{TP}{TP+FN}$\n",
    "\n",
    "##### Precision:  The ability of a model to identify only the relevant data points.\n",
    "$Precision = \\frac{TP}{TP+FP}$\n",
    "\n",
    "##### F1 Score: optimal blend of precision and recall \n",
    "$F1 = \\frac{2*Recall*Precision}{Sensitivity + Recall}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The team will meet every week to check in on each other’s progress\n",
    "- All decision making will be made with a majority vote\n",
    "- The team will communicate primarily on Discord and will report the status of their part of the work if necessary\n",
    "- Keep each other accountable for deadlines decided as a team ( most likely the day of the meeting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/24  | Before 11:59 PM  |  Work on project proposal (Taylor)  | Turni in project proposal |\n",
    "| 5/4  | 7:00 PM  | NA   | Discuss Project Idea, Work on Proposal |\n",
    "| 5/19  | 5:00 PM  | Work on Proposal   | Project Checkpoint, Clean Up Dataset, Rediscuss model selection |\n",
    "| 5/21  | 4:00 PM  | Work on Checkpoint   | Run data through model, compare/evaluate models |\n",
    "| 6/1  | 4:00 PM  | Model Optimization  | Final Writeup, Evaluate Final Model Performance |\n",
    "| 6/11  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
